##### This is the code for Lab 4 ####

library(ggfortify)
library(e1071)
library(class)
library(psych)

# PCA with wine dataset
wine <- read.csv("~/Desktop/wine/wine.data", header=FALSE)
View(wine)
names(wine) <- c("Type","Alcohol","Malic acid","Ash","Alcalinity of ash","Magnesium","Total phenols","Flavanoids","Nonflavanoid Phenols","Proanthocyanins","Color Intensity","Hue","Od280/od315 of diluted wines","Proline")
head(wine)
wine$Type <- as.factor(wine$Type)
wine <- wine[,-c(4,5,10)]
pairs.panels(wine[,-1],gap = 0,bg = c("red", "yellow", "blue")[wine$Type],pch=21)

#get rid of wine type here
wine.X <- wine[,2:11]
#compute the PCs
wine.X
principal_components <- princomp(wine.X, cor = TRUE, score = TRUE)
summary(principal_components)
plot(principal_components)

#plot the dataset using the 1st and 2nd PCs
# plotting the pc using the a line in plot() functions 
plot(principal_components, type = "l")
# using rhw biplot() function we can plot the components
biplot(principal_components)
## using autoplot() function to plot the components
autoplot(principal_components, data = wine, colour = 'Type',
         loadings = TRUE, loadings.colour = 'blue',
         loadings.label = TRUE, loadings.label.size = 3)
# loadings
principal_components$loadings

#Identify the variables that contribute the most to the 1st PC.
wine.pc <- prcomp(wine[,-1], center = TRUE, scale. = TRUE)
attributes(wine.pc)
summary(wine.pc)
wine.pc$rotation
#the variable that contributes most to the 1st PC is Nonflavanoid Phenols

#Train a classifier model to predict wine type using the 11 attributes.
# sample 124 values from 178 (~70%) 
s_myvars <- sample(178,124)
## number of rows
n <- nrow(wine)
## training set indexes
train.indexes <- sample(n, n*.7)
## create training/test sets
wine.train <-wine[train.indexes,]
wine.test <-wine[-train.indexes,]
sqrt(124) 
k = 11
KNNpred <- knn(train = wine.train[1:11], test = wine.test[1:11], cl = wine.train$Type, k = k)
# create contingency table/ confusion matrix 
contingency.table1 <- table(KNNpred,wine.test$Type)
contingency.matrix1 = as.matrix(contingency.table1) 
sum(diag(contingency.matrix1))/length(wine$Type)
accuracy <- c()
ks <- c(1,2,3,4,5)
for (k in ks) {
  KNNpred <- knn(train = wine.train[1:11], test = wine.test[1:11], cl = wine.train$Type, k = k) 
  cm = as.matrix(table(Actual=KNNpred, Predicted = wine.test$Type, dnn=list('predicted','actual'))) 
  accuracy <- c(accuracy,sum(diag(cm))/length(wine.test$Type))
}
plot(ks,accuracy,type = "b", ylim = c(0,1)) +
  title("kNN Graph 1")
#Evaluate the model using a contingency matrix and calculate the accuracy of correct classifications.
print(contingency.table1)
print(accuracy)

#Train a classifier model to predict wine type using the data projected into the first 3 PCs.
# use PCA but only with the  3PCs 
wine_pca <- wine.pc$x[, 1:3] # Use the first 3 principal components

#Train a classifier model
# sample 124 values from 178 (~70%) 
s_myvars2 <- sample(178,124)
## number of rows
n <- nrow(wine_pca)
## training set indexes
train.indexes.2 <- sample(n, n*.7)
## create training/test sets
wine.train2 <-wine_pca[train.indexes.2,]
wine.test2 <-wine_pca[-train.indexes.2,]
train.classes = wine$Type[train.indexes.2]
test.classes = wine$Type[-train.indexes.2]
sqrt(124) 
k = 11
KNNpred <- knn(train = wine.train2[,1:3], test = wine.test2[,1:3], cl = train.classes, k = k)
# create contingency table/ confusion matrix 
contingency.table2 <- table(KNNpred,test.classes)
contingency.matrix2 = as.matrix(contingency.table2) 
sum(diag(contingency.matrix2))/length(test.classes)
accuracy <- c()
ks <- c(1,2,3,4)
for (k in ks) {
  KNNpred <- knn(train = wine.train2[,1:3], test = wine.test2[,1:3], cl = train.classes, k = k) 
  cm = as.matrix(table(Actual=KNNpred, Predicted = test.classes, dnn=list('predicted','actual'))) 
  accuracy <- c(accuracy,sum(diag(cm))/length(test.classes))
}
plot(ks,accuracy,type = "b", ylim = c(0.5,1.2)) +
  title("kNN Graph 2")
#Evaluate the model using a contingency matrix and calculate the accuracy of correct classifications.
print(contingency.table2)
print(accuracy)

#Drop the variables least contributing to the 1st PC 
#the variable that least contributes to the 1st PC is Flavanoids 
wine.new <- wine[,c(2:5,7:11)]
#Re-run PCA
wine.new
principal_components2 <- princomp(wine.new, cor = TRUE, score = TRUE)
summary(principal_components2)
plot(principal_components2)
# plotting the pc using the a line in plot() functions 
plot(principal_components2, type = "l")
# using rhw biplot() function we can plot the components
biplot(principal_components2)
## using autoplot() function to plot the components
autoplot(principal_components2, data = wine, colour = 'Type',
         loadings = TRUE, loadings.colour = 'blue',
         loadings.label = TRUE, loadings.label.size = 3)
# loadings
principal_components2$loadings

#Identify the variables that contribute the most to the 1st PC.
wine.pc2 <- prcomp(wine.new, center = TRUE, scale. = TRUE)
attributes(wine.pc2)
summary(wine.pc2)
wine.pc2$rotation

#Train a classifier model to predict wine type using the data projected into the first 3 PCs after rerunning PCA.
# sample 124 values from 178 (~70%) 
s_myvars3 <- sample(178,124)
## number of rows
n <- nrow(wine.new)
## training set indexes
train.indexes.3 <- sample(n, n*.7)
## create training/test sets
wine.train3 <-wine.new[train.indexes.3,]
wine.test3 <-wine.new[-train.indexes.3,]
train.classes2 = wine$Type[train.indexes.3]
test.classes2 = wine$Type[-train.indexes.3]
sqrt(124) 
k = 11
KNNpred <- knn(train = wine.train3[,1:9], test = wine.test3[,1:9], cl = train.classes2, k = k)
# create contingency table/ confusion matrix 
# create contingency table/ confusion matrix 
contingency.table3 <- table(KNNpred,test.classes2)
contingency.matrix3 = as.matrix(contingency.table3) 
sum(diag(contingency.matrix2))/length(test.classes2)
accuracy <- c()
ks <- c(1,2,3,4)
for (k in ks) {
  KNNpred <- knn(train = wine.train3[,1:3], test = wine.test3[,1:3], cl = train.classes2, k = k) 
  cm = as.matrix(table(Actual=KNNpred, Predicted = test.classes2, dnn=list('predicted','actual'))) 
  accuracy <- c(accuracy,sum(diag(cm))/length(test.classes2))
}
plot(ks,accuracy,type = "b", ylim = c(0.5,1)) +
  title("kNN Graph 3")
#Evaluate the model using a contingency matrix and calculate the accuracy of correct classifications.
print(contingency.table3)
print(accuracy)

#Compare the 3 classification models using contingency tables and prevision/recall/f1 metrics
#precision recall for classifier full model
cm = as.matrix(table(Actual=KNNpred, Predicted = wine.test$Type, dnn=list('predicted','actual'))) 
cm
n = sum(cm) # number of instances
nc = nrow(cm) # number of classes
diag = diag(cm) # number of correctly classified instances per class 
rowsums = apply(cm, 1, sum) # number of instances per class
colsums = apply(cm, 2, sum) # number of predictions per class
p = rowsums / n # distribution of instances over the actual classes
q = colsums / n # distribution of instances over the predicted 
recall = diag / rowsums 
precision = diag / colsums
f1 = 2 * precision * recall / (precision + recall) 
data.frame(recall, precision, f1)
#precision recall for classifier for new pca
cm = as.matrix(table(Actual=KNNpred, Predicted = test.classes, dnn=list('predicted','actual'))) 
cm
n = sum(cm) # number of instances
nc = nrow(cm) # number of classes
diag = diag(cm) # number of correctly classified instances per class 
rowsums = apply(cm, 1, sum) # number of instances per class
colsums = apply(cm, 2, sum) # number of predictions per class
p = rowsums / n # distribution of instances over the actual classes
q = colsums / n # distribution of instances over the predicted 
recall = diag / rowsums 
precision = diag / colsums
f1 = 2 * precision * recall / (precision + recall) 
data.frame(recall, precision, f1)
#precision recall for classifier post new pca
cm = as.matrix(table(Actual=KNNpred, Predicted = test.classes2, dnn=list('predicted','actual'))) 
cm
n = sum(cm) # number of instances
nc = nrow(cm) # number of classes
diag = diag(cm) # number of correctly classified instances per class 
rowsums = apply(cm, 1, sum) # number of instances per class
colsums = apply(cm, 2, sum) # number of predictions per class
p = rowsums / n # distribution of instances over the actual classes
q = colsums / n # distribution of instances over the predicted 
recall = diag / rowsums 
precision = diag / colsums
f1 = 2 * precision * recall / (precision + recall) 
data.frame(recall, precision, f1)
## the best model is the one created using the first 3 PC values according to the precision and recall tables/values
